# 备忘录

[json.dumps](https://blog.csdn.net/weixin_38842821/article/details/108359551)

```python
josn.dumps(ensure_ascii=True) ensure_ascii=True： # 默认输出ASCLL码，如果把这个该成False,就可以输出中文
```



**mysql 排序**

使用时间进行排序时一定注意，如果出现瞬间批量插入的情况，他们的时间都是一样的，那么查询时就可能会出现乱序（分页时），最好使用联合排序，**保证唯一性**



**pandas**

```python
df = pd.Dataframe()
df['b'].tolist()

# axis = 1 列， axis = 0 行

aa.sort_values(['c','b'],ascending=[False,False]) # 排序

# 行之间拼接
pd.concat(df1,df2,sort=False) # 是否重置索引

# 重置索引
df1.reset_index()

# 分组，分组后一般需要重置索引，分组时会将条件设置为索引，而在合并时索引会被舍弃
df1.group(['id, name']).reset_index() # 

pd.merge(left, right, on='id', how='left')

# 增加列，
df1['new'] = [1,2,3,4]



# 数据信息查看
df.shape #查看维度
df.dtypes # 查看数据类型
df['age'].unique() # 查看age唯一值
df.head(5) # 查看前5行数据
df.tail(5) # 查看最后5行数据

# 数据清洗与预处理
df.dropna(how='any',inplace=True) # 空值处理删除
df.fillna(0) # 空值处理填充
df['name'] = df['name'].map(str.strip) # 空格处理
df.['age'].astype('int') # 更改数据类型
df.rename(columns={'name':'名字','age':'年龄'}) # 更改列名称
df['cabin'].drop_duplicates(keep='last') # 删除重复值
df['name'].replace('C','c', inplace=True) # 数据替换

# 数据提取，技巧
df.loc[:2,'age'] # 按标签进行提取,取 age 列的前两行
df.iloc[:2,3] # 按位置提取，取第四列的前两行
df['group'].isin(['high']) # 按指定条件对数据进行提取
```



**获取子查询参数**

```sql
select t.id form (select id, name) as t where id=1
```



vote_analyze

```
# print(df.to_dict('records'))
# df.where(df.notnull(), None, inplace=True)
import numpy as np
# df.replace(np.nan, None, inplace=True)
```



#### 待解决问题

pandas 合并中，同为object类型 merge 的结果不对

```python
    a = pd.DataFrame({'account_id': ['107595537', '107595537', '107595537'], 'lecture_id': ['1111261928', '1111261929', '1111261930'], 'access_status': [1, 1, 1]})

b = pd.DataFrame([1111261928, 1111261929, 1111261930], columns=['lecture_id'], dtype=object)

pd.merge(b,a,on='lecture_id',how='left')  # 出错

# 解决办法 转为 int 
access_lecture_df['lecture_id'] = pd.to_numeric(access_lecture_df['lecture_id']).fillna(0)
```



shift + alt + a 自定义截屏 ，修改后双击 保存到粘贴板



**cmq迁移**

> log, wk_router

1. rpc基类
2. zk配置 config

**单元测试未修改**



**log脚本迁移**
数据服务2 pm2 23个脚本
archive_liveroom_content_access
process_finish_rate
process_lecturer_message
process_stat * 10
process_stat_to_db



md5的应用



==结营报告推送时间和生成时间配置到 wk_config 中==

**cmq迁移 **  20220613 下周一

==数据准确，数据去重，数据量级问题，预留出预发布测试时间==

1. 去重
2. 判空
3. 字符检查，整形判断， 关键词的防SQL注入
3. 数量限制

---

交易分析

invoice_id 不是主键，都可以重复

显示当前时间段下的支付时间最近的10个商品 时间可能相同，可用 id，pay_time 共同排序





```sql
1. 同一个人两笔订单是否可以是同一个商品

data = account_id in () or invoice_id in ()

3account = data.acc in account_ids   用户的三部分
	3account_df.group_by('refund_status')

unmatch_account = account_ids - 3accout 未匹配到订单的用户

unmatch_account_orders = data.acc - 3account 订单未匹配到用户信息的订单

```



==RpcClient为什么要封装请求类==





#### **待办事项**

- sql 的联合与常用函数,与 case 等，以及 调优，[根据小时进行分组](https://blog.csdn.net/weixin_44217672/article/details/111152084)
- zookeeper 消息批处理，数据库相关，redis ,mysql
- 上下文管理 contextvars  https://zhuanlan.zhihu.com/p/65896031
- 写一个自动格式化csv文件的脚本，方便navicate导入数据
- **celery**, **调度系统**
- **kafka**
- nginx推流配置 
- ffmpeg 流媒体
- opencv
- 解决高并发场景下锁冲突的问题





