##### 或许本地笔记和博客是不同的东西，本地博客供自己记录知识，查找知识点，而博客就是交流的地方，自己查找知识的时候并不是在博客查，而是在本地查，博客就是要把自己似懂非懂的东西输出，交流提升。



#### post的额外用法

```python
post的URL中的拼接部分实际是没有用处的，并不会参与请求，但是可以用来存储一些信息。
```



#### 预执行函数？？？

![image-20220928155450315](../resource/image-20220928155450315.png)

每一个都写对应的函数，难以阅读，使用偏函数又难以定位具体函数，（如a,b，再写一个执行器，）







##### 聚合数据

应该想十方那样将数据聚合到一张表中，便于查询，便于定位问题是逻辑问题还是数据问题



#### 时间处理-定时器：

- [优化-处理大量定时任务的思路_大量定时任务处理方法](https://blog.csdn.net/MrCoderStack/article/details/88548584)
- [定时任务时间表达式的规则](https://www.cnblogs.com/wangning528/p/8315916.html)



#### 长链接转短连接

> 需要一个短连接服务器，短连接服务经301（永久）/302（临时）重定向后，再转向真实的长链接地址，有点可能是隐蔽安全，这些参数可以经过网关过滤一层，而且可以包含更多的参数（get请求）

**参考：**

- https://blog.csdn.net/mangomango123/article/details/119910256





#### 反射可以解决 if 判断太多的情况

加字典映射



#### 状态的修改

在调度系统与下载系统中，关于状态的转换大致思路是，用数字表示各种状态，但是都是使用 字符串形态的数字，手动选择赋值，或许可以使用二进制数据表示状态的修改，像权限系统一样。



#### 分发与调度系统

> 应用于需要延时调用，重复调用的情况

流程

1. 应用端创建标准格式的任务包

   > 任务包要有一个具体的任务模型类（最少的数据条件创建一个大致的实例）

   - 创建任务是否需要同时持久化任务？
   - 创建任务是否直接放在缓存中？，后续从缓存中获取任务

2. 调用分发系统创建正式的调度的任务，并将状态响应给应用端（back_ground)

   > 正式调度任务包在分发系统中丰富具体信息

3. 调度系统处理调度任务

   > 对正式任务包做处理， 直接从接口获取任务包，放入celery中处理

   - 如果之前将任务持久化入db, 更新任务状态
   - 如果直接处理任务，怎么更新任务状态？（内部接口应该可以实现 celery flower）

4. 脚本补偿之类的



**其他情况**：

1. 需要在任意时间，任意状态，获取某一个任务的当前信息（状态，数据）
2. 需要在任意时间，任意状态，修改某一个任务（更新，暂停，终止，删除）

**原有实现：**

1. 在wsgi文件中从缓存中取出待处理任务包，是则使用注册对象的方式循环调用drainor的处理接口（相当于一个循环脚本）
2. 在drainor中处理完任务后又重新调用了dispatcher的更新接口（update_process_result）用于更新任务中台
3. drainor中为什么要有预处理？



**要求：**

1. 兼容历史业务
2. 状态可监控

**实现细节：**

1. 一个任务进入调度系统，

   > 两种情况

   ```python
   # 1. 直接调用接口创建任务，这种必然是第一次创建，所以是缓存第一种格式
   
   # 2. 从redis或者kafka中取出数据
   ```
   
   
   
2. 先经过一段封装，然后缓存到redis中

   > 缓存两种格式
   >
   > 即时任务直接缓存
   >
   > 延时任务根据延时时间判断是持久化还是直接缓存
   >
   > ```
   > 设定一个持久化与与缓存的阈值，大于这个阈值就持久化，否则就直接缓存在redis中，需要有一个脚本，每次扫描在这个阈值以内的数据，缓存到redis，
   > 这个扫描频率小于阈值
   > ```

   ```python
   # 1. 一种是完整的任务格式，包含一条应该入库的处理记录所有的字段
   {
       "id": 111,
       "state": "success",
       "type": "int",
       "time": "1111"
   }
   
   #另一种只有主键和状态
   {
       "id": 111,
       "state": "success"
   }
   ```

3. 然后再celery中执行处理函数，收集任务状态，将这些状态实时的更新到redis中，

   > 当进行状态更新的时候使用lua脚本，lua脚本处理逻辑是，
   >
   > 1. 根据主键，如果redis缓存中可以找到具体任务，那么就更新第一种任务的转态，
   >
   > 2. 如果找不到具体任务，那么就插入一条新的记录（主键：转态）
   >
   >    - 插入一条新纪录
   >
   >    - 更新之前的一条记录，
   >
   >      > 只是没有具体任务而已，这样也是可以的，只是插入的时候覆盖了之前的记录，可以使用redis的setnx，如果有则更新，没有则插入），
   >
   > 这里选择**定时加定量**的方法更新缓存（因为定时可能会出现短时间大量人物涌入的情况，造成内存压力，定量的话有可能会出现任务稀疏，状态更新不及时的情况），
   >
   > 更新缓存这里应该是一个脚本

4. 持久化记录

   > 根据之前的两种格式，使用不同的方法批量更新缓存。



==111==

**参与同步系统的开发维护**

同步系统是一个监控系统，通过cannal监控mysql数据表的binlog增量，通过kafka消费，通知到相关业务侧，为数据的聚合和部分业务场景提供支持。

- 项目技术：

 



#### 权限系统

cusbin



#### 错误排查

- 解释器，三方库的版本问题，包含一些已经解决的bug，像是 pandas 的 to_dict('record')



#### 一些待解决的问题

1. super 的用法，为什么可以 return super ？

2. 什么是通用方法？它的定义是什么？

   逻辑相同的公共部分，不涉及业务？通用方法并不是公共方法

3. 数据库分库分表问题



#### 数据库读写分离

> 场景：用户下了一笔订单，但没有立刻支付，以后还可能多次查看这笔订单，但都没有支付，只有最后一次支付了，

这就会出现需要反复查表，然后写表的操作，分为两个库表，一个写表，一个读表，使用一个脚本单独用于同步数据



#### 应该注意的

1. 数据库建表时应该标明个人信息，哪个字段是谁修改的，为什么修改（加一个字段）
1. fastapi-libs中的 CacheInfo 类，分别定义了 key, timeout字段，但是直接使用redis的原生方法，那么这个类几乎没有用处，应该避免

### 一些疑问：

1. 分布式锁和普通锁（单机锁）的区别？

   参考：[(145条消息) 如何用Redis实现分布式锁_GeorgiaStar的博客-CSDN博客_redis做分布式锁](https://blog.csdn.net/fuzhongmin05/article/details/119251590)

   ```python
   普通锁是基于内存的，在分布式服务，多进程服务中会出现消息不共用的情况，而想要实现分布式锁，必须借助一个外部系统，所有进程都去这个系统上申请加锁。分布式锁可以使用redis实现
   
   # 分布式锁的安全性
   安全性在于原子性，只有操作是原子性才能确保所得安全性，确保安全性的方法包括：
   1. redis 自身支持 ex nx 操作，将设置锁和设置过期时间捆绑为原子性操作。
   2. 使用 Lua 脚本，一个 Lua 脚本的执行是原子性的，而且性能更优异
   3. 使用 Redisson 利用看门狗自动延时机制避免锁过期导致的问题
   ```

   
   
   
   
   