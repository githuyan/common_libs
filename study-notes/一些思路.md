##### 或许本地笔记和博客是不同的东西，本地博客供自己记录知识，查找知识点，而博客就是交流的地方，自己查找知识的时候并不是在博客查，而是在本地查，博客就是要把自己似懂非懂的东西输出，交流提升。

---

---



### 备忘录

#### 一些待解决的问题

1. 了解现在架构现状和趋势

2. 设计模式在实际中的应用

3. SQL的开发与优化

4. web后端开发技术，协议，架构，存储，缓存，安全

5. ==调度系统部署==

6. ==同步系统开发==

   > 履约任务之类的，个体的状态影响整体的状态，所有子任务结束，那么任务主体也应该自动结束，airflow脚本也应用在这种情况，如果这个主体属于一个更大的主体，那么这个主体结束，会造成很多层的联动效应，这就需要kafka监控底层变化，调动多个平行脚本，或者调动一个airflow有向无环图脚本，底层主体结束，一层层向上查询, 或者跟时间有关自动完结的任务

7. ==airflow脚本系统学习==， 学习airflow配合celery

8. 性能优化图

9. 自定义pandas缺失值，NaT

10. 封装SQL源语执行接口，防止SQL注入

11. 数据库分库分表问题

12. rpc协议规范， grpc 和 websocket及其前后端通信机制

13. 缓存层冷热分离，（网关？）

14. 池化，熔断，限流（网关的作用？istio）



#### 值得学习的地方

1. 关于异常捕获，构造一个上下文进行异常捕获

   > 尽量不要全局捕获，最好是精确捕获，异常捕获操作耗时只跟是否捕获到异常和是否精确捕获有关

2. 回调函数的使用，

   > 也许需要创建一个装备了回调的基类，所有继承了这个类的结构都可以自由的配置回调函数
   
3. 代理的用处

   > 只有一个一对一的服务如果做到多个服务公用（打造一个一对多的代理）

#### 有问题的地方

1. 在没有外键的情况下，表之间，字段之间的关系不明确，主要是没有清晰的文档，表结构设计很多冗余字段，字段意义不明确
1. 废弃字段的删除，开发环境和测试环境之前库表的同步 ，数据不清空，字段直接删除，很容易出问题
1. 尽量减少不明意义的数据表隐式同步（回调函数，同步脚本），有也一定要有非常清晰的标识，非常清晰的文档，不然表中数据的变更或者业务中数据难以溯源
1. 有一些格式不统一，导致出现意料之外的问题
1. 数据库的设计中应该有一些扩展字段，这些扩展字段也许并不只是为了填充信息，比如一个循环脚本，我们发现了bug，现在要调试，我们就可以在扩展字段填充信息，通过这个字段进行筛选执行，这样调试更有效率



#### 需要注意的地方

1. ##### 补偿脚本的引入

   事务的缺失，由于业务中会有无法原子性的操作，如网络操作与数据库操作，这时需要设置补偿脚本，或者增加事务（**慎用**）

2. ##### SQL防注入

   ```python
   sql = f""" select * form {self.table} """
   self.execute(sql)  # 直接执行SQL可能会有SQL注入的风险
   
   sql = f""" select * from %s """
   self.execute(sql, params=[self.table]) # 参数化查询，预编译不会将参数作为SQL语句的一部分，只会作为一个属性
   ```
   
3. **调度系统的作用**

   创建多个副本处理任务
   
4. 数据库每一个表都**至少应该有一个业务的唯一字段**， 否则扩展艰难

5. 格式统一很重要，比如时间的传递格式，"2022-02-02" 和 "2022-02-02 12:12:12" 不能够便捷的通用转换，很容易出问题 ==？？==

5. 鉴权，越权问题如何阻止？一个人能查看别人的数据信息


​	

---

---



关于架构还是应该需要一个数据库管理层，db层负责处理SQL，一些拼接问题之类的，只负责拼接并返回一条用于执行的最终SQL，而数据库管理层才是真正的调用层，这样的架构便于单测，便于拆解， 分层很有必要，必须固化分层，起码会便于单测



##### 聚合数据

应该想十方那样将数据聚合到一张表中，便于查询，便于定位问题是逻辑问题还是数据问题



#### 时间处理-定时器：

- [优化-处理大量定时任务的思路_大量定时任务处理方法](https://blog.csdn.net/MrCoderStack/article/details/88548584)
- [定时任务时间表达式的规则](https://www.cnblogs.com/wangning528/p/8315916.html)



#### 长链接转短连接

> 需要一个短连接服务器，短连接服务经301（永久）/302（临时）重定向后，再转向真实的长链接地址，优点可能是隐蔽安全，这些参数可以经过网关过滤一层，而且可以包含更多的参数（get请求）

**参考：**

- https://blog.csdn.net/mangomango123/article/details/119910256





#### 反射可以解决 if 判断太多的情况

加字典映射



==111==

**参与同步系统的开发维护**

同步系统是一个监控系统，通过cannal监控mysql数据表的binlog增量，通过kafka消费，通知到相关业务侧，为数据的聚合和部分业务场景提供支持。

- 项目技术：

 



#### 权限系统

cusbin



#### 错误排查

- 解释器，三方库的版本问题，包含一些已经解决的bug，像是 pandas 的 to_dict('record')



#### 应该注意的

1. 数据库建表时应该标明个人信息，哪个字段是谁修改的，为什么修改（加一个字段）
1. fastapi-libs中的 CacheInfo 类，分别定义了 key, timeout字段，但是直接使用redis的原生方法，那么这个类几乎没有用处，应该避免

### 一些疑问：

1. 分布式锁和普通锁（单机锁）的区别？

   参考：[(145条消息) 如何用Redis实现分布式锁_GeorgiaStar的博客-CSDN博客_redis做分布式锁](https://blog.csdn.net/fuzhongmin05/article/details/119251590)

   ```python
   普通锁是基于内存的，在分布式服务，多进程服务中会出现消息不共用的情况，而想要实现分布式锁，必须借助一个外部系统，所有进程都去这个系统上申请加锁。分布式锁可以使用redis实现
   
   # 分布式锁的安全性
   安全性在于原子性，只有操作是原子性才能确保锁的安全性，确保安全性的方法包括：
   1. redis 自身支持 ex nx 操作，将设置锁和设置过期时间捆绑为原子性操作。
   2. 使用 Lua 脚本，一个 Lua 脚本的执行是原子性的，而且性能更优异
   3. 使用 Redisson 利用看门狗自动延时机制避免锁过期导致的问题
   ```

