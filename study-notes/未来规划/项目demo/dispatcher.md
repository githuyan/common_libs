### 分发与调度系统

> 应用于需要延时调用，重复调用的情况

流程

1. 应用端创建标准格式的任务包

   > 任务包要有一个具体的任务模型类（最少的数据条件创建一个大致的实例）

   - 创建任务是否需要同时持久化任务？
   - 创建任务是否直接放在缓存中？，后续从缓存中获取任务

2. 调用分发系统创建正式的调度的任务，并将状态响应给应用端（back_ground)

   > 正式调度任务包在分发系统中丰富具体信息

3. 调度系统处理调度任务

   > 对正式任务包做处理， 直接从接口获取任务包，放入celery中处理

   - 如果之前将任务持久化入db, 更新任务状态
   - 如果直接处理任务，怎么更新任务状态？（内部接口应该可以实现 celery flower）

4. 脚本补偿之类的



**其他情况**：

1. 需要在任意时间，任意状态，获取某一个任务的当前信息（状态，数据）
2. 需要在任意时间，任意状态，修改某一个任务（更新，暂停，终止，删除）

**原有实现：**

1. 在wsgi文件中从缓存中取出待处理任务包，是则使用注册对象的方式循环调用drainor的处理接口（相当于一个循环脚本）
2. 在drainor中处理完任务后又重新调用了dispatcher的更新接口（update_process_result）用于更新任务中台
3. drainor中为什么要有预处理？



**要求：**

1. 兼容历史业务
2. 状态可监控

**实现细节：**

1. 一个任务进入调度系统，

   > 两种情况

   ```python
   # 1. 直接调用接口创建任务，这种必然是第一次创建，所以是缓存第一种格式
   
   # 2. 从redis或者kafka中取出数据
   ```

   

2. 先经过一段封装，然后缓存到redis中

   > 缓存两种格式
   >
   > 即时任务直接缓存
   >
   > 延时任务根据延时时间判断是持久化还是直接缓存
   >
   > ```
   > 设定一个持久化与与缓存的阈值，大于这个阈值就持久化，否则就直接缓存在redis中，需要有一个脚本，每次扫描在这个阈值以内的数据，缓存到redis，
   > 这个扫描频率小于阈值
   > ```

   ```python
   # 1. 一种是完整的任务格式，包含一条应该入库的处理记录所有的字段
   {
       "id": 111,
       "state": "success",
       "type": "int",
       "time": "1111"
   }
   
   #另一种只有主键和状态
   {
       "id": 111,
       "state": "success"
   }
   ```

3. 然后再celery中执行处理函数，收集任务状态，将这些状态实时的更新到redis中，

   > 当进行状态更新的时候使用lua脚本，lua脚本处理逻辑是，
   >
   > 1. 根据主键，如果redis缓存中可以找到具体任务，那么就更新第一种任务的转态，
   >
   > 2. 如果找不到具体任务，那么就插入一条新的记录（主键：转态）
   >
   >    - 插入一条新纪录
   >
   >    - 更新之前的一条记录，
   >
   >      > 只是没有具体任务而已，这样也是可以的，只是插入的时候覆盖了之前的记录，可以使用redis的setnx，如果有则更新，没有则插入），
   >
   > 这里选择**定时加定量**的方法更新缓存（因为定时可能会出现短时间大量人物涌入的情况，造成内存压力，定量的话有可能会出现任务稀疏，状态更新不及时的情况），
   >
   > 更新缓存这里应该是一个脚本

4. 持久化记录

   > 根据之前的两种格式，使用不同的方法批量更新缓存。

